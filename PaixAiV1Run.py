import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

device = torch.device('cpu')

# 1. ì €ì¥ëœ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_path = "./path/to/saved/model"
tokenizer_path = "./path/to/saved/tokenizer"

model = AutoModelForSequenceClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)

# 2. ë¬¸ì¥ ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
def sentence_predict(sent):
    # 3. í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½
    model.eval()

    # 4. ì…ë ¥ ë¬¸ì¥ í† í°í™”
    tokenized_sent = tokenizer(
        sent,
        return_tensors="pt",
        truncation=True,
        add_special_tokens=True,
        max_length=128
    )

    # 5. GPUë¡œ ëª¨ë¸ ì´ë™
    tokenized_sent.to(device)

    # 6. ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(
            input_ids=tokenized_sent["input_ids"],
            attention_mask=tokenized_sent["attention_mask"],
            token_type_ids=tokenized_sent["token_type_ids"]
        )

    # 7. ê²°ê³¼ ë°˜í™˜
    logits = outputs[0]
    logits = logits.detach().cpu()
    result = logits.argmax(-1)
    if result == 0:
        result = " >> ì•…ì˜ì ì¸ ëŒ“ê¸€ ğŸ‘¿"
    elif result == 1:
        result = " >> ì¼ë°˜ ëŒ“ê¸€ ğŸ˜€"
    return result

# 8. ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ë£¨í”„
while True:
    sentence = input("ëŒ“ê¸€ì„ ì…ë ¥í•˜ì„¸ìš” (0ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œ): ")
    if sentence == "0":
        break
    print(sentence_predict(sentence))
    print("\n")

